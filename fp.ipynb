{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntokens, emsize, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(emsize, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, emsize)\n",
    "        self.emsize = emsize\n",
    "        self.decoder = nn.Linear(emsize, ntokens)\n",
    "        self.ntokens = ntokens\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, verbose=False):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.emsize)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        self.store = output.detach().numpy().copy()\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data(song_strings, num_songs):\n",
    "    notes = list(\"ABCDEFGHIJ\")\n",
    "    chord = [[i] for i in range(10)]\n",
    "    source = []\n",
    "    target = []\n",
    "    for s in range(num_songs):\n",
    "        for i in range(40):\n",
    "            sentence = [chord[notes.index(song_strings[s][(i + j) % 40])][0] for j in range(4)]\n",
    "            answer = [chord[notes.index(song_strings[s][(i + j + 1) % 40])][0] for j in range(4)]\n",
    "            source.append(sentence)\n",
    "            target.append(answer)\n",
    "    return np.array(source), np.array(target)\n",
    "\n",
    "def predict(model, source):\n",
    "    model.eval()\n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        src = source.transpose(0, 1)\n",
    "        output = model(src)\n",
    "        predictions = output.argmax(dim=2)\n",
    "    return predictions.transpose(0, 1).numpy()\n",
    "\n",
    "def generate_predictions(model, source):\n",
    "    all_predictions = []\n",
    "    for i in range(80):\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "    return np.array(all_predictions)\n",
    "\n",
    "def generate_source_for_next_model(model, source):\n",
    "    all_predictions = []\n",
    "    source_39 = np.array(source[39]).reshape(1, -1)\n",
    "    predictions_39 = predict(model, source_39)\n",
    "    all_predictions.append(predictions_39)\n",
    "\n",
    "    for i in range(39):\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    source_79 = np.array(source[79]).reshape(1, -1)\n",
    "    predictions_79 = predict(model, source_79)\n",
    "    all_predictions.append(predictions_79)\n",
    "\n",
    "    for i in range(40, 79):\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "    return all_predictions\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    pred_tensor = torch.tensor(pred.reshape(-1, pred.shape[-1]), dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    correct = (pred_tensor == target_tensor).sum().item()\n",
    "    total = target_tensor.numel()\n",
    "    return correct / total * 100\n",
    "\n",
    "def train_model(model, source, target, num_epochs, learning_rate):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        src = source_tensor.transpose(0, 1)\n",
    "        tgt = target_tensor.transpose(0, 1)\n",
    "        output = model(src)\n",
    "        loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1\n",
      "Model 1 Accuracy: 87.50%\n",
      "Training Model 2\n",
      "Model 2 Accuracy: 82.50%\n",
      "Training Model 3\n",
      "Model 3 Accuracy: 77.50%\n",
      "Training Model 4\n",
      "Model 4 Accuracy: 73.75%\n",
      "Training Model 5\n",
      "Model 5 Accuracy: 70.00%\n",
      "Training Model 6\n",
      "Model 6 Accuracy: 67.50%\n",
      "Training Model 7\n",
      "Model 7 Accuracy: 63.75%\n",
      "Training Model 8\n",
      "Model 8 Accuracy: 63.75%\n",
      "Training Model 9\n",
      "Model 9 Accuracy: 62.50%\n",
      "Training Model 10\n",
      "Model 10 Accuracy: 60.00%\n",
      "Model 1 Accuracy: 87.50%\n",
      "Model 2 Accuracy: 82.50%\n",
      "Model 3 Accuracy: 77.50%\n",
      "Model 4 Accuracy: 73.75%\n",
      "Model 5 Accuracy: 70.00%\n",
      "Model 6 Accuracy: 67.50%\n",
      "Model 7 Accuracy: 63.75%\n",
      "Model 8 Accuracy: 63.75%\n",
      "Model 9 Accuracy: 62.50%\n",
      "Model 10 Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "ntokens = 10\n",
    "emsize = 20\n",
    "nhead = 4\n",
    "d_hid = 20\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 10\n",
    "\n",
    "song_strings = np.array([\n",
    "    \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\",\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\",\n",
    "])\n",
    "\n",
    "# Initial data\n",
    "source, target = get_training_data(song_strings, 2)\n",
    "accuracies = []\n",
    "\n",
    "# Training loop for 30 models\n",
    "for model_idx in range(num_models):\n",
    "    print(f\"Training Model {model_idx + 1}\")\n",
    "\n",
    "    # Train model\n",
    "    model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model = train_model(model, source, target, num_epochs, learning_rate)\n",
    "\n",
    "    # Generate predictions and calculate accuracy\n",
    "    pred = generate_predictions(model, source)\n",
    "    accuracy = calculate_accuracy(pred, target)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Model {model_idx + 1} Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model\n",
    "    model_dir = f\"model_{model_idx + 1}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_save_path = os.path.join(model_dir, f'model_{model_idx + 1}.pt')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # Generate source for the next model\n",
    "    source = generate_source_for_next_model(model, source)\n",
    "\n",
    "# Print all accuracies\n",
    "for idx, acc in enumerate(accuracies):\n",
    "    print(f\"Model {idx + 1} Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1\n",
      "Model 1 Accuracy: 87.50%\n",
      "Training Model 2\n",
      "Model 2 Accuracy: 83.75%\n",
      "Training Model 3\n",
      "Model 3 Accuracy: 83.75%\n",
      "Training Model 4\n",
      "Model 4 Accuracy: 82.50%\n",
      "Training Model 5\n",
      "Model 5 Accuracy: 77.50%\n",
      "Training Model 6\n",
      "Model 6 Accuracy: 73.75%\n",
      "Training Model 7\n",
      "Model 7 Accuracy: 68.75%\n",
      "Training Model 8\n",
      "Model 8 Accuracy: 67.50%\n",
      "Training Model 9\n",
      "Model 9 Accuracy: 70.00%\n",
      "Training Model 10\n",
      "Model 10 Accuracy: 63.75%\n",
      "Model 1 Accuracy: 87.50%\n",
      "Model 2 Accuracy: 83.75%\n",
      "Model 3 Accuracy: 83.75%\n",
      "Model 4 Accuracy: 82.50%\n",
      "Model 5 Accuracy: 77.50%\n",
      "Model 6 Accuracy: 73.75%\n",
      "Model 7 Accuracy: 68.75%\n",
      "Model 8 Accuracy: 67.50%\n",
      "Model 9 Accuracy: 70.00%\n",
      "Model 10 Accuracy: 63.75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "ntokens = 10\n",
    "emsize = 8\n",
    "nhead = 2\n",
    "d_hid = 8\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 10\n",
    "\n",
    "song_strings = np.array([\n",
    "    \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\",\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\",\n",
    "])\n",
    "\n",
    "# Initial data\n",
    "source, target = get_training_data(song_strings, 2)\n",
    "accuracies = []\n",
    "\n",
    "# Training loop for 30 models\n",
    "for model_idx in range(num_models):\n",
    "    print(f\"Training Model {model_idx + 1}\")\n",
    "\n",
    "    # Train model\n",
    "    model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model = train_model(model, source, target, num_epochs, learning_rate)\n",
    "\n",
    "    # Generate predictions and calculate accuracy\n",
    "    pred = generate_predictions(model, source)\n",
    "    accuracy = calculate_accuracy(pred, target)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Model {model_idx + 1} Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model\n",
    "    model_dir = f\"model_{model_idx + 1}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_save_path = os.path.join(model_dir, f'model_{model_idx + 1}.pt')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # Generate source for the next model\n",
    "    source = generate_source_for_next_model(model, source)\n",
    "\n",
    "# Print all accuracies\n",
    "for idx, acc in enumerate(accuracies):\n",
    "    print(f\"Model {idx + 1} Accuracy: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
