{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.03, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=20, out_features=20, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=20, out_features=20, bias=True)\n",
      "        (dropout): Dropout(p=0.03, inplace=False)\n",
      "        (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
      "        (norm1): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.03, inplace=False)\n",
      "        (dropout2): Dropout(p=0.03, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): Embedding(8, 20)\n",
      "  (decoder): Linear(in_features=20, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntokens, emsize, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(emsize, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, emsize)\n",
    "        self.emsize = emsize\n",
    "        self.decoder = nn.Linear(emsize, ntokens)\n",
    "        self.ntokens=ntokens\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src,verbose=False):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.emsize)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        self.store=output.detach().numpy().copy()\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Parameters\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 20  # embedding dimension\n",
    "nhead = 4  # number of heads in the nn.MultiheadAttention\n",
    "d_hid = 20  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer\n",
    "dropout = 0.03  # dropout probability\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(songStrings, nrOfSongs):\n",
    "    notes = list(\"ABCDEFGHIJ\")\n",
    "    chord = [[0], [1], [2], [3], [4], [5], [6], [7],[8],[9]]\n",
    "    source = []\n",
    "    target = []\n",
    "    for s in range(nrOfSongs):\n",
    "        for i in range(40):\n",
    "            sentence = []\n",
    "            answer = []\n",
    "            for j in range(4):\n",
    "                sentence.append(chord[notes.index(songStrings[s][(i+j)%40])][0])\n",
    "                answer.append(chord[notes.index(songStrings[s][(i+j+1)%40])][0])\n",
    "            source.append(sentence)\n",
    "            target.append(answer)\n",
    "    return np.array(source), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4) (80, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data generation and preparation\n",
    "songStrings = np.array([\n",
    "   \n",
    "    \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "    # \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\", # daisybells\n",
    "    # \"ABCDEFGHIEABCDEFGHIEABCDEFGHIEABCDEFGHIEAB\", # 10th note E\n",
    "    # \"ABCDAFGHIJBCDEAGHIAFCDEFIHIABADEFGCIABCBEF\", # 5th note different random\n",
    "    # \"ABCDAFGHIAABCDAFGHIAABCDAFGHIAABCDAFGHIAAB\" # 5th note different\n",
    "\n",
    "])\n",
    "\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "print(source.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1: [0 1 2 3]\n",
      "Target 1: [1 2 3 4]\n",
      "\n",
      "Source 2: [1 2 3 4]\n",
      "Target 2: [2 3 4 5]\n",
      "\n",
      "Source 3: [2 3 4 5]\n",
      "Target 3: [3 4 5 6]\n",
      "\n",
      "Source 4: [3 4 5 6]\n",
      "Target 4: [4 5 6 7]\n",
      "\n",
      "Source 5: [4 5 6 7]\n",
      "Target 5: [5 6 7 8]\n",
      "\n",
      "Source 6: [5 6 7 8]\n",
      "Target 6: [6 7 8 9]\n",
      "\n",
      "Source 7: [6 7 8 9]\n",
      "Target 7: [7 8 9 0]\n",
      "\n",
      "Source 8: [7 8 9 0]\n",
      "Target 8: [8 9 0 1]\n",
      "\n",
      "Source 9: [8 9 0 1]\n",
      "Target 9: [9 0 1 2]\n",
      "\n",
      "Source 10: [9 0 1 2]\n",
      "Target 10: [0 1 2 3]\n",
      "\n",
      "Source 11: [0 1 2 3]\n",
      "Target 11: [1 2 3 4]\n",
      "\n",
      "Source 12: [1 2 3 4]\n",
      "Target 12: [2 3 4 5]\n",
      "\n",
      "Source 13: [2 3 4 5]\n",
      "Target 13: [3 4 5 6]\n",
      "\n",
      "Source 14: [3 4 5 6]\n",
      "Target 14: [4 5 6 7]\n",
      "\n",
      "Source 15: [4 5 6 7]\n",
      "Target 15: [5 6 7 8]\n",
      "\n",
      "Source 16: [5 6 7 8]\n",
      "Target 16: [6 7 8 9]\n",
      "\n",
      "Source 17: [6 7 8 9]\n",
      "Target 17: [7 8 9 0]\n",
      "\n",
      "Source 18: [7 8 9 0]\n",
      "Target 18: [8 9 0 1]\n",
      "\n",
      "Source 19: [8 9 0 1]\n",
      "Target 19: [9 0 1 2]\n",
      "\n",
      "Source 20: [9 0 1 2]\n",
      "Target 20: [0 1 2 3]\n",
      "\n",
      "Source 21: [0 1 2 3]\n",
      "Target 21: [1 2 3 4]\n",
      "\n",
      "Source 22: [1 2 3 4]\n",
      "Target 22: [2 3 4 5]\n",
      "\n",
      "Source 23: [2 3 4 5]\n",
      "Target 23: [3 4 5 6]\n",
      "\n",
      "Source 24: [3 4 5 6]\n",
      "Target 24: [4 5 6 7]\n",
      "\n",
      "Source 25: [4 5 6 7]\n",
      "Target 25: [5 6 7 8]\n",
      "\n",
      "Source 26: [5 6 7 8]\n",
      "Target 26: [6 7 8 9]\n",
      "\n",
      "Source 27: [6 7 8 9]\n",
      "Target 27: [7 8 9 0]\n",
      "\n",
      "Source 28: [7 8 9 0]\n",
      "Target 28: [8 9 0 1]\n",
      "\n",
      "Source 29: [8 9 0 1]\n",
      "Target 29: [9 0 1 2]\n",
      "\n",
      "Source 30: [9 0 1 2]\n",
      "Target 30: [0 1 2 3]\n",
      "\n",
      "Source 31: [0 1 2 3]\n",
      "Target 31: [1 2 3 4]\n",
      "\n",
      "Source 32: [1 2 3 4]\n",
      "Target 32: [2 3 4 5]\n",
      "\n",
      "Source 33: [2 3 4 5]\n",
      "Target 33: [3 4 5 6]\n",
      "\n",
      "Source 34: [3 4 5 6]\n",
      "Target 34: [4 5 6 7]\n",
      "\n",
      "Source 35: [4 5 6 7]\n",
      "Target 35: [5 6 7 8]\n",
      "\n",
      "Source 36: [5 6 7 8]\n",
      "Target 36: [6 7 8 9]\n",
      "\n",
      "Source 37: [6 7 8 9]\n",
      "Target 37: [7 8 9 0]\n",
      "\n",
      "Source 38: [7 8 9 0]\n",
      "Target 38: [8 9 0 1]\n",
      "\n",
      "Source 39: [8 9 0 1]\n",
      "Target 39: [9 0 1 2]\n",
      "\n",
      "Source 40: [9 0 1 2]\n",
      "Target 40: [0 1 2 3]\n",
      "\n",
      "Source 41: [9 8 7 6]\n",
      "Target 41: [8 7 6 5]\n",
      "\n",
      "Source 42: [8 7 6 5]\n",
      "Target 42: [7 6 5 4]\n",
      "\n",
      "Source 43: [7 6 5 4]\n",
      "Target 43: [6 5 4 3]\n",
      "\n",
      "Source 44: [6 5 4 3]\n",
      "Target 44: [5 4 3 2]\n",
      "\n",
      "Source 45: [5 4 3 2]\n",
      "Target 45: [4 3 2 1]\n",
      "\n",
      "Source 46: [4 3 2 1]\n",
      "Target 46: [3 2 1 0]\n",
      "\n",
      "Source 47: [3 2 1 0]\n",
      "Target 47: [2 1 0 9]\n",
      "\n",
      "Source 48: [2 1 0 9]\n",
      "Target 48: [1 0 9 8]\n",
      "\n",
      "Source 49: [1 0 9 8]\n",
      "Target 49: [0 9 8 7]\n",
      "\n",
      "Source 50: [0 9 8 7]\n",
      "Target 50: [9 8 7 6]\n",
      "\n",
      "Source 51: [9 8 7 6]\n",
      "Target 51: [8 7 6 5]\n",
      "\n",
      "Source 52: [8 7 6 5]\n",
      "Target 52: [7 6 5 4]\n",
      "\n",
      "Source 53: [7 6 5 4]\n",
      "Target 53: [6 5 4 3]\n",
      "\n",
      "Source 54: [6 5 4 3]\n",
      "Target 54: [5 4 3 2]\n",
      "\n",
      "Source 55: [5 4 3 2]\n",
      "Target 55: [4 3 2 1]\n",
      "\n",
      "Source 56: [4 3 2 1]\n",
      "Target 56: [3 2 1 0]\n",
      "\n",
      "Source 57: [3 2 1 0]\n",
      "Target 57: [2 1 0 9]\n",
      "\n",
      "Source 58: [2 1 0 9]\n",
      "Target 58: [1 0 9 8]\n",
      "\n",
      "Source 59: [1 0 9 8]\n",
      "Target 59: [0 9 8 7]\n",
      "\n",
      "Source 60: [0 9 8 7]\n",
      "Target 60: [9 8 7 6]\n",
      "\n",
      "Source 61: [9 8 7 6]\n",
      "Target 61: [8 7 6 5]\n",
      "\n",
      "Source 62: [8 7 6 5]\n",
      "Target 62: [7 6 5 4]\n",
      "\n",
      "Source 63: [7 6 5 4]\n",
      "Target 63: [6 5 4 3]\n",
      "\n",
      "Source 64: [6 5 4 3]\n",
      "Target 64: [5 4 3 2]\n",
      "\n",
      "Source 65: [5 4 3 2]\n",
      "Target 65: [4 3 2 1]\n",
      "\n",
      "Source 66: [4 3 2 1]\n",
      "Target 66: [3 2 1 0]\n",
      "\n",
      "Source 67: [3 2 1 0]\n",
      "Target 67: [2 1 0 9]\n",
      "\n",
      "Source 68: [2 1 0 9]\n",
      "Target 68: [1 0 9 8]\n",
      "\n",
      "Source 69: [1 0 9 8]\n",
      "Target 69: [0 9 8 7]\n",
      "\n",
      "Source 70: [0 9 8 7]\n",
      "Target 70: [9 8 7 6]\n",
      "\n",
      "Source 71: [9 8 7 6]\n",
      "Target 71: [8 7 6 5]\n",
      "\n",
      "Source 72: [8 7 6 5]\n",
      "Target 72: [7 6 5 4]\n",
      "\n",
      "Source 73: [7 6 5 4]\n",
      "Target 73: [6 5 4 3]\n",
      "\n",
      "Source 74: [6 5 4 3]\n",
      "Target 74: [5 4 3 2]\n",
      "\n",
      "Source 75: [5 4 3 2]\n",
      "Target 75: [4 3 2 1]\n",
      "\n",
      "Source 76: [4 3 2 1]\n",
      "Target 76: [3 2 1 0]\n",
      "\n",
      "Source 77: [3 2 1 0]\n",
      "Target 77: [2 1 0 9]\n",
      "\n",
      "Source 78: [2 1 0 9]\n",
      "Target 78: [1 0 9 8]\n",
      "\n",
      "Source 79: [1 0 9 8]\n",
      "Target 79: [0 9 8 7]\n",
      "\n",
      "Source 80: [0 9 8 7]\n",
      "Target 80: [9 8 7 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to print all source and target pairs\n",
    "def print_all_source_target_pairs(source, target):\n",
    "    for i in range(len(source)):\n",
    "        print(f\"Source {i+1}: {source[i]}\")\n",
    "        print(f\"Target {i+1}: {target[i]}\")\n",
    "        print()\n",
    "\n",
    "# Print all source and target pairs\n",
    "print_all_source_target_pairs(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, source):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "        output = model(src)  # Compute the output\n",
    "        predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "    return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training parameters\n",
    "ntokens = 10\n",
    "emsize = 20\n",
    "nhead = 4\n",
    "d_hid = 20\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 1  # Train 30 different models\n",
    "\n",
    "songStrings = np.array([\n",
    "   \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "])\n",
    "\n",
    "# Train and save multiple models\n",
    "for model_idx in range(num_models):\n",
    "    model_dir = f\"forward_prediction/model_{model_idx}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    source, target = getTrainingData(songStrings, 2)\n",
    "    source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src = source_tensor.transpose(0, 1)\n",
    "        tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "        output = model(src)\n",
    "        loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_save_path = os.path.join(model_dir, 'model.pt')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4) (80, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data generation and preparation\n",
    "songStrings = np.array([\n",
    "   \n",
    "    \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJAB\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJI\", # reverse\n",
    "    # \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\", # daisybells\n",
    "    # \"ABCDEFGHIEABCDEFGHIEABCDEFGHIEABCDEFGHIEAB\", # 10th note E\n",
    "    # \"ABCDAFGHIJBCDEAGHIAFCDEFIHIABADEFGCIABCBEF\", # 5th note different random\n",
    "    # \"ABCDAFGHIAABCDAFGHIAABCDAFGHIAABCDAFGHIAAB\" # 5th note different\n",
    "\n",
    "])\n",
    "\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "print(source.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, source):\n",
    "    \"\"\"\n",
    "    Generate and save predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "    save_path (str): The path to save the predictions file.\n",
    "    \"\"\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 80):  # Loop from 0 to 38 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_predictions(model, source, save_path=\"predictions.npy\"):\n",
    "    \"\"\"\n",
    "    Generate and save predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "    save_path (str): The path to save the predictions file.\n",
    "    \"\"\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict for source[39] first\n",
    "    source_39 = np.array(source[39]).reshape(1, -1)\n",
    "    predictions_39 = predict(model, source_39)\n",
    "    all_predictions.append(predictions_39)\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 39):  # Loop from 0 to 38 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Predict for source[79] first\n",
    "    source_79 = np.array(source[79]).reshape(1, -1)\n",
    "    predictions_79 = predict(model, source_79)\n",
    "    all_predictions.append(predictions_79)\n",
    "\n",
    "    # Predict and save predictions for source[40] to source[78]\n",
    "    for i in range(40, 79):  # Loop from 40 to 78 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    # Save the predictions for use in the second model\n",
    "    np.save(save_path, all_predictions)\n",
    "\n",
    "    print(\"All predictions have been saved for further use.\")\n",
    "\n",
    "    return all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[3, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[3, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[3, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[3, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions have been saved for further use.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "source_2 = generate_and_save_predictions(model, source, save_path=\"predictions.npy\")\n",
    "type(source_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43msource_2\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source_2' is not defined"
     ]
    }
   ],
   "source": [
    "type(source_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[9, 2, 3, 4]],\n",
       "\n",
       "       [[0, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[7, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[8, 1, 2, 3]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[7, 4, 3, 2]],\n",
       "\n",
       "       [[6, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[0, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "pred = generate_predictions(model, source)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_from_saved_predictions(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing saved predictions with the target.\n",
    "    \n",
    "    Args:\n",
    "    predictions_path (str): The path to the saved predictions file.\n",
    "    target (np.ndarray): The true target data.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    # Load the predictions from the file\n",
    "    all_predictions = pred\n",
    "    \n",
    "    # Flatten the predictions to match the target shape\n",
    "    all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "    \n",
    "    # Convert predictions and target to tensors\n",
    "    pred_tensor = torch.tensor(all_predictions, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (pred_tensor == target_tensor).sum().item()\n",
    "    total = target_tensor.numel()\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Load the original target data\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "# Ensure the target matches the number of predictions\n",
    "target = target[:len(pred_2)]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy_from_saved_predictions(pred_2, target)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3110098838806152\n",
      "Epoch 100, Loss: 1.0287226438522339\n",
      "Epoch 200, Loss: 0.45679640769958496\n",
      "Epoch 300, Loss: 0.3288688063621521\n",
      "Epoch 400, Loss: 0.290780246257782\n",
      "Epoch 500, Loss: 0.28136831521987915\n",
      "Epoch 600, Loss: 0.2604230046272278\n",
      "Epoch 700, Loss: 0.2678636610507965\n",
      "Epoch 800, Loss: 0.2603604793548584\n",
      "Epoch 900, Loss: 0.2513199746608734\n",
      "Epoch 1000, Loss: 0.25223198533058167\n",
      "Epoch 1100, Loss: 0.25624531507492065\n",
      "Epoch 1200, Loss: 0.258869469165802\n",
      "Epoch 1300, Loss: 0.2518995404243469\n",
      "Epoch 1400, Loss: 0.26028168201446533\n",
      "Epoch 1500, Loss: 0.24723899364471436\n",
      "Epoch 1600, Loss: 0.25782880187034607\n",
      "Epoch 1700, Loss: 0.24713537096977234\n",
      "Epoch 1800, Loss: 0.2524046301841736\n",
      "Epoch 1900, Loss: 0.2471456527709961\n",
      "Training of the second model completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the TransformerModel class is already defined and available\n",
    "\n",
    "# Load the predictions from the first model\n",
    "all_predictions = np.load(\"predictions.npy\")\n",
    "\n",
    "# Flatten the predictions to match the expected input format for training\n",
    "all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "\n",
    "# Load the original target data\n",
    "_, target = getTrainingData(songStrings, 2)\n",
    "target = target[:len(all_predictions)]  # Ensure the target matches the number of predictions\n",
    "\n",
    "# Convert predictions and target to tensors\n",
    "source_tensor = torch.tensor(all_predictions, dtype=torch.long)\n",
    "target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "# Define the second model\n",
    "model_2 = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "# Set the model to training mode\n",
    "model_2.train()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Transpose the source and target tensors to match the model's expected input dimensions\n",
    "    src = source_tensor.transpose(0, 1)\n",
    "    tgt = target_tensor.transpose(0, 1)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model_2(src)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(output.view(-1, model_2.ntokens), tgt.reshape(-1))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training of the second model completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions have been saved for further use.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "source_3 = generate_and_save_predictions(model_2, source_2, save_path=\"predictions.npy\")\n",
    "source_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[5, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[9, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[6, 7, 8, 9]],\n",
       "\n",
       "       [[3, 8, 9, 0]],\n",
       "\n",
       "       [[4, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[4, 1, 2, 3]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]],\n",
       "\n",
       "       [[8, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[4, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[3, 2, 1, 0]],\n",
       "\n",
       "       [[6, 1, 0, 9]],\n",
       "\n",
       "       [[5, 0, 9, 8]],\n",
       "\n",
       "       [[4, 9, 8, 7]],\n",
       "\n",
       "       [[9, 8, 7, 6]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "pred_2 = generate_predictions(model_2, source_2)\n",
    "pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Load the original target data\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "# Ensure the target matches the number of predictions\n",
    "target = target[:len(pred_2)]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy_from_saved_predictions(pred_2, target)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getTrainingData(songStrings, nrOfSongs):\n",
    "    notes = list(\"ABCDEFGHIJ\")\n",
    "    chord = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]\n",
    "    source = []\n",
    "    target = []\n",
    "    for s in range(nrOfSongs):\n",
    "        for i in range(40):  # Updated to 40 notes\n",
    "            sentence = []\n",
    "            answer = []\n",
    "            for j in range(4):\n",
    "                sentence.append(chord[notes.index(songStrings[s][(i+j)%40])][0])\n",
    "                answer.append(chord[notes.index(songStrings[s][(i+j+1)%40])][0])\n",
    "            source.append(sentence)\n",
    "            target.append(answer)\n",
    "    return np.array(source), np.array(target)\n",
    "\n",
    "# def predict(model, source):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     source = torch.tensor(source, dtype=torch.long)\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "#         output = model(src)  # Compute the output\n",
    "#         predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "#     return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n",
    "\n",
    "# def predict(model, source):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     source = torch.tensor(source, dtype=torch.long).unsqueeze(1)  # Add batch dimension\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "#         output = model(src)  # Compute the output\n",
    "#         predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "#     return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n",
    "# def predict(model, source):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     source = torch.tensor(source, dtype=torch.long).unsqueeze(1)  # Add batch dimension\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "#         output = model(src)  # Compute the output\n",
    "#         predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "#     return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n",
    "def predict(model, source):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    source = torch.tensor(source, dtype=torch.long).unsqueeze(1)  # Add batch dimension\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "        output = model(src)  # Compute the output\n",
    "        predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "    return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n",
    "\n",
    "def generate_predictions(model, source):\n",
    "    \"\"\"\n",
    "    Generate predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The predictions.\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 80):  # Loop from 0 to 79 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "def generate_and_save_predictions(model, source):\n",
    "    \"\"\"\n",
    "    Generate and save predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "    save_path (str): The path to save the predictions file.\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict for source[39] first\n",
    "    source_39 = np.array(source[39]).reshape(1, -1)\n",
    "    predictions_39 = predict(model, source_39)\n",
    "    all_predictions.append(predictions_39)\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 39):  # Loop from 0 to 38 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Predict for source[79] first\n",
    "    source_79 = np.array(source[79]).reshape(1, -1)\n",
    "    predictions_79 = predict(model, source_79)\n",
    "    all_predictions.append(predictions_79)\n",
    "\n",
    "    # Predict and save predictions for source[40] to source[78]\n",
    "    for i in range(40, 79):  # Loop from 40 to 78 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing saved predictions with the target.\n",
    "    \n",
    "    Args:\n",
    "    predictions_path (str): The path to the saved predictions file.\n",
    "    target (np.ndarray): The true target data.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    # Load the predictions from the file\n",
    "    all_predictions = pred\n",
    "    \n",
    "    # Flatten the predictions to match the target shape\n",
    "    all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "    \n",
    "    # Convert predictions and target to tensors\n",
    "    pred_tensor = torch.tensor(all_predictions, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (pred_tensor == target_tensor).sum().item()\n",
    "    total = target_tensor.numel()\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# def train_model(model, source, target, num_epochs=2000, learning_rate=1e-3):\n",
    "#     \"\"\"\n",
    "#     Train the model on the given source and target data.\n",
    "    \n",
    "#     Args:\n",
    "#     model (nn.Module): The model to train.\n",
    "#     source (np.ndarray): The source data.\n",
    "#     target (np.ndarray): The target data.\n",
    "#     num_epochs (int): The number of epochs to train.\n",
    "#     learning_rate (float): The learning rate for the optimizer.\n",
    "    \n",
    "#     Returns:\n",
    "#     nn.Module: The trained model.\n",
    "#     \"\"\"\n",
    "#     model.train()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "#     target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         src = source_tensor.transpose(0, 1)\n",
    "#         tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "#         output = model(src)\n",
    "#         loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if epoch % 100 == 0:\n",
    "#             # Generate predictions for the entire dataset\n",
    "#             pred = output.argmax(dim=2).transpose(0, 1).detach().numpy()\n",
    "#             accuracy = calculate_accuracy(pred, target)\n",
    "#             print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "#     return model\n",
    "# def train_model(model, source, target, num_epochs=2000, learning_rate=1e-3):\n",
    "#     model.train()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "#     target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         src = source_tensor.transpose(0, 1)\n",
    "#         tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "#         output = model(src)\n",
    "#         loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if epoch % 100 == 0:\n",
    "#             pred = output.argmax(dim=2).transpose(0, 1).detach().numpy()\n",
    "#             accuracy = calculate_accuracy(pred, target)\n",
    "#             print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "#     return model\n",
    "# def train_model(model, source, target, num_epochs=2000, learning_rate=1e-3):\n",
    "#     model.train()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "#     target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Ensure src and tgt are correctly shaped [sequence_length, batch_size]\n",
    "#         src = source_tensor.transpose(0, 1)\n",
    "#         tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "#         # Debugging: Print shapes of src and tgt\n",
    "#         print(f\"Epoch {epoch}, src shape: {src.shape}, tgt shape: {tgt.shape}\")\n",
    "\n",
    "#         # Forward pass\n",
    "#         output = model(src)\n",
    "\n",
    "#         # Debugging: Print shape of output\n",
    "#         print(f\"Epoch {epoch}, output shape: {output.shape}\")\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if epoch % 100 == 0:\n",
    "#             pred = output.argmax(dim=2).transpose(0, 1).detach().numpy()\n",
    "#             accuracy = calculate_accuracy(pred, target)\n",
    "#             print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "#     return model\n",
    "def train_model(model, source, target, num_epochs=2000, learning_rate=1e-3):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure src and tgt are correctly shaped [sequence_length, batch_size]\n",
    "        src = source_tensor.transpose(0, 1)\n",
    "        tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "        # Debugging: Print shapes of src and tgt\n",
    "        if epoch % 100 == 0:  # Print every 100 epochs\n",
    "            print(f\"Epoch {epoch}, src shape: {src.shape}, tgt shape: {tgt.shape}\")\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src)\n",
    "\n",
    "        # Debugging: Print shape of output\n",
    "        if epoch % 100 == 0:  # Print every 100 epochs\n",
    "            print(f\"Epoch {epoch}, output shape: {output.shape}\")\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output.view(-1, model.ntokens), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            pred = output.argmax(dim=2).transpose(0, 1).detach().numpy()\n",
    "            accuracy = calculate_accuracy(pred, target)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 0, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 0, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 0, Loss: 2.3171732425689697, Accuracy: 9.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 100, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 100, Loss: 0.83387291431427, Accuracy: 82.81%\n",
      "Epoch 200, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 200, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 200, Loss: 0.32683008909225464, Accuracy: 84.69%\n",
      "Epoch 300, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 300, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 300, Loss: 0.2322976142168045, Accuracy: 87.19%\n",
      "Epoch 400, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 400, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 400, Loss: 0.20433561503887177, Accuracy: 88.12%\n",
      "Epoch 500, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 500, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 500, Loss: 0.19401873648166656, Accuracy: 88.44%\n",
      "Epoch 600, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 600, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 600, Loss: 0.19568553566932678, Accuracy: 86.88%\n",
      "Epoch 700, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 700, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 700, Loss: 0.19840502738952637, Accuracy: 85.31%\n",
      "Epoch 800, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 800, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 800, Loss: 0.19833442568778992, Accuracy: 85.62%\n",
      "Epoch 900, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 900, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 900, Loss: 0.17949528992176056, Accuracy: 90.62%\n",
      "Epoch 1000, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1000, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1000, Loss: 0.1954888105392456, Accuracy: 85.00%\n",
      "Epoch 1100, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1100, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1100, Loss: 0.180393785238266, Accuracy: 87.81%\n",
      "Epoch 1200, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1200, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1200, Loss: 0.1836225390434265, Accuracy: 88.12%\n",
      "Epoch 1300, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1300, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1300, Loss: 0.1801266074180603, Accuracy: 89.06%\n",
      "Epoch 1400, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1400, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1400, Loss: 0.18002542853355408, Accuracy: 87.81%\n",
      "Epoch 1500, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1500, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1500, Loss: 0.18242935836315155, Accuracy: 85.94%\n",
      "Epoch 1600, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1600, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1600, Loss: 0.17851999402046204, Accuracy: 88.12%\n",
      "Epoch 1700, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1700, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1700, Loss: 0.18851082026958466, Accuracy: 85.94%\n",
      "Epoch 1800, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1800, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1800, Loss: 0.1765221804380417, Accuracy: 89.38%\n",
      "Epoch 1900, src shape: torch.Size([4, 80]), tgt shape: torch.Size([4, 80])\n",
      "Epoch 1900, output shape: torch.Size([4, 80, 10])\n",
      "Epoch 1900, Loss: 0.18119676411151886, Accuracy: 86.88%\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "query should be unbatched 2D or batched 3D tensor but received 4-D query tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_path)\n\u001b[0;32m---> 30\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m calculate_accuracy(pred, target)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy of model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 67\u001b[0m, in \u001b[0;36mgenerate_predictions\u001b[0;34m(model, source)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m80\u001b[39m):  \u001b[38;5;66;03m# Loop from 0 to 79 inclusive\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     current_source \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(source[i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m     current_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     all_predictions\u001b[38;5;241m.\u001b[39mappend(current_predictions)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Convert all_predictions to a numpy array for easier handling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 47\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, source)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No need to track gradients\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     src \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Adjust for the expected input dimensions [sequence_length, batch_size]\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute the output\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Get the index of the max log-probability\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memsize)\n\u001b[1;32m     33\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m---> 34\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:5227\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   5198\u001b[0m         multi_head_attention_forward,\n\u001b[1;32m   5199\u001b[0m         tens_ops,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5224\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   5225\u001b[0m     )\n\u001b[0;32m-> 5227\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[43m_mha_shape_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5229\u001b[0m \u001b[38;5;66;03m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[1;32m   5230\u001b[0m \u001b[38;5;66;03m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[1;32m   5231\u001b[0m \u001b[38;5;66;03m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n\u001b[1;32m   5232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   5233\u001b[0m     \u001b[38;5;66;03m# unsqueeze if the input is unbatched\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:5054\u001b[0m, in \u001b[0;36m_mha_shape_check\u001b[0;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[1;32m   5051\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m expected_shape, \\\n\u001b[1;32m   5052\u001b[0m                 (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `attn_mask` shape to be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5053\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5054\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   5055\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery should be unbatched 2D or batched 3D tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D query tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_batched\n",
      "\u001b[0;31mAssertionError\u001b[0m: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor"
     ]
    }
   ],
   "source": [
    "# # Training parameters\n",
    "ntokens = 10\n",
    "emsize = 20\n",
    "nhead = 4\n",
    "d_hid = 20\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 5  # Number of models to train sequentially\n",
    "\n",
    "songStrings = np.array([\n",
    "   \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "])\n",
    "\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "for model_idx in range(num_models):\n",
    "    print(f\"Training model {model_idx + 1}\")\n",
    "\n",
    "    model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model = train_model(model, source, target, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "    model_dir = f\"forward_prediction/model_{model_idx}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_save_path = os.path.join(model_dir, 'model.pt')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    pred = generate_predictions(model, source)\n",
    "    accuracy = calculate_accuracy(pred, target)\n",
    "    print(f\"Accuracy of model {model_idx + 1}: {accuracy:.2f}%\")\n",
    "\n",
    "    source = generate_and_save_predictions(model, source)\n",
    "\n",
    "    source = source.reshape(-1, source.shape[-1])\n",
    "\n",
    "print(\"Training of all models completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
