{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.03, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=20, out_features=20, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=20, out_features=20, bias=True)\n",
      "        (dropout): Dropout(p=0.03, inplace=False)\n",
      "        (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
      "        (norm1): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.03, inplace=False)\n",
      "        (dropout2): Dropout(p=0.03, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): Embedding(8, 20)\n",
      "  (decoder): Linear(in_features=20, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntokens, emsize, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(emsize, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, emsize)\n",
    "        self.emsize = emsize\n",
    "        self.decoder = nn.Linear(emsize, ntokens)\n",
    "        self.ntokens=ntokens\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src,verbose=False):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.emsize)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        self.store=output.detach().numpy().copy()\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Parameters\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 20  # embedding dimension\n",
    "nhead = 4  # number of heads in the nn.MultiheadAttention\n",
    "d_hid = 20  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer\n",
    "dropout = 0.03  # dropout probability\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(songStrings, nrOfSongs):\n",
    "    notes = list(\"ABCDEFGHIJ\")\n",
    "    chord = [[0], [1], [2], [3], [4], [5], [6], [7],[8],[9]]\n",
    "    source = []\n",
    "    target = []\n",
    "    for s in range(nrOfSongs):\n",
    "        for i in range(40):\n",
    "            sentence = []\n",
    "            answer = []\n",
    "            for j in range(4):\n",
    "                sentence.append(chord[notes.index(songStrings[s][(i+j)%40])][0])\n",
    "                answer.append(chord[notes.index(songStrings[s][(i+j+1)%40])][0])\n",
    "            source.append(sentence)\n",
    "            target.append(answer)\n",
    "    return np.array(source), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4) (80, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data generation and preparation\n",
    "songStrings = np.array([\n",
    "   \n",
    "    \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "    # \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\", # daisybells\n",
    "    # \"ABCDEFGHIEABCDEFGHIEABCDEFGHIEABCDEFGHIEAB\", # 10th note E\n",
    "    # \"ABCDAFGHIJBCDEAGHIAFCDEFIHIABADEFGCIABCBEF\", # 5th note different random\n",
    "    # \"ABCDAFGHIAABCDAFGHIAABCDAFGHIAABCDAFGHIAAB\" # 5th note different\n",
    "\n",
    "])\n",
    "\n",
    "source, target = getTrainingData(songStrings, 2)\n",
    "\n",
    "print(source.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, source):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "        output = model(src)  # Compute the output\n",
    "        predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "    return predictions.transpose(0, 1).numpy()  # Return predictions in original input format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_current_model(model, source):\n",
    "    \"\"\"\n",
    "    Generate and save predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "    save_path (str): The path to save the predictions file.\n",
    "    \"\"\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 80):  # Loop from 0 to 38 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_source_for_next_model(model, source):\n",
    "    \"\"\"\n",
    "    Generate and save predictions for the specified source sequences.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model to use for predictions.\n",
    "    source (np.ndarray): The source sequences to generate predictions from.\n",
    "    save_path (str): The path to save the predictions file.\n",
    "    \"\"\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Predict for source[39] first\n",
    "    source_39 = np.array(source[39]).reshape(1, -1)\n",
    "    predictions_39 = predict(model, source_39)\n",
    "    all_predictions.append(predictions_39)\n",
    "\n",
    "    # Predict and save predictions for source[1] to source[38]\n",
    "    for i in range(0, 39):  # Loop from 0 to 38 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Predict for source[79] first\n",
    "    source_79 = np.array(source[79]).reshape(1, -1)\n",
    "    predictions_79 = predict(model, source_79)\n",
    "    all_predictions.append(predictions_79)\n",
    "\n",
    "    # Predict and save predictions for source[40] to source[78]\n",
    "    for i in range(40, 79):  # Loop from 40 to 78 inclusive\n",
    "        current_source = np.array(source[i]).reshape(1, -1)\n",
    "        current_predictions = predict(model, current_source)\n",
    "        all_predictions.append(current_predictions)\n",
    "\n",
    "    # Convert all_predictions to a numpy array for easier handling\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "\n",
    "    return all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing saved predictions with the target.\n",
    "    \n",
    "    Args:\n",
    "    predictions_path (str): The path to the saved predictions file.\n",
    "    target (np.ndarray): The true target data.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    # Load the predictions from the file\n",
    "    all_predictions = pred\n",
    "    \n",
    "    # Flatten the predictions to match the target shape\n",
    "    all_predictions = all_predictions.reshape(-1, all_predictions.shape[-1])\n",
    "    \n",
    "    # Convert predictions and target to tensors\n",
    "    pred_tensor = torch.tensor(all_predictions, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (pred_tensor == target_tensor).sum().item()\n",
    "    total = target_tensor.numel()\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training parameters\n",
    "ntokens = 10\n",
    "emsize = 20\n",
    "nhead = 4\n",
    "d_hid = 20\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 1  # Train 30 different models\n",
    "\n",
    "songStrings = np.array([\n",
    "   \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "])\n",
    "\n",
    "# Train and save multiple models\n",
    "for model_idx in range(num_models):\n",
    "    model_dir = f\"forward_prediction/model_1\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_1 = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model_1.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "\n",
    "    source, target = getTrainingData(songStrings, 2)\n",
    "    source_tensor = torch.tensor(source, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src = source_tensor.transpose(0, 1)\n",
    "        tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "        output = model_1(src)\n",
    "        loss = criterion(output.view(-1, model_1.ntokens), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_save_path = os.path.join(model_dir, 'model_1.pt')\n",
    "    torch.save(model_1.state_dict(), model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[4, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[4, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[4, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6, 7]],\n",
       "\n",
       "       [[5, 6, 7, 8]],\n",
       "\n",
       "       [[4, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[8, 9, 0, 1]],\n",
       "\n",
       "       [[7, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 3]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[0, 7, 6, 5]],\n",
       "\n",
       "       [[7, 6, 5, 4]],\n",
       "\n",
       "       [[8, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[4, 3, 2, 1]],\n",
       "\n",
       "       [[5, 2, 1, 0]],\n",
       "\n",
       "       [[4, 1, 0, 9]],\n",
       "\n",
       "       [[1, 0, 9, 8]],\n",
       "\n",
       "       [[2, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "pred_1 = generate_predictions_for_current_model(model_1, source)\n",
    "pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(pred_1, target)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "source_2 = generate_source_for_next_model(model_1, source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [1, 4, 5, 6],\n",
       "       [4, 5, 6, 7],\n",
       "       [5, 6, 7, 8],\n",
       "       [4, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [8, 9, 0, 1],\n",
       "       [7, 0, 1, 2],\n",
       "       [0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [1, 4, 5, 6],\n",
       "       [4, 5, 6, 7],\n",
       "       [5, 6, 7, 8],\n",
       "       [4, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [8, 9, 0, 1],\n",
       "       [7, 0, 1, 2],\n",
       "       [0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [1, 4, 5, 6],\n",
       "       [4, 5, 6, 7],\n",
       "       [5, 6, 7, 8],\n",
       "       [4, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [8, 9, 0, 1],\n",
       "       [7, 0, 1, 2],\n",
       "       [0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [1, 4, 5, 6],\n",
       "       [4, 5, 6, 7],\n",
       "       [5, 6, 7, 8],\n",
       "       [4, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [8, 9, 0, 1],\n",
       "       [7, 0, 1, 2],\n",
       "       [1, 8, 7, 6],\n",
       "       [0, 7, 6, 5],\n",
       "       [7, 6, 5, 4],\n",
       "       [8, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [4, 3, 2, 1],\n",
       "       [5, 2, 1, 0],\n",
       "       [4, 1, 0, 9],\n",
       "       [1, 0, 9, 8],\n",
       "       [2, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [0, 7, 6, 5],\n",
       "       [7, 6, 5, 4],\n",
       "       [8, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [4, 3, 2, 1],\n",
       "       [5, 2, 1, 0],\n",
       "       [4, 1, 0, 9],\n",
       "       [1, 0, 9, 8],\n",
       "       [2, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [0, 7, 6, 5],\n",
       "       [7, 6, 5, 4],\n",
       "       [8, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [4, 3, 2, 1],\n",
       "       [5, 2, 1, 0],\n",
       "       [4, 1, 0, 9],\n",
       "       [1, 0, 9, 8],\n",
       "       [2, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [0, 7, 6, 5],\n",
       "       [7, 6, 5, 4],\n",
       "       [8, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [4, 3, 2, 1],\n",
       "       [5, 2, 1, 0],\n",
       "       [4, 1, 0, 9],\n",
       "       [1, 0, 9, 8],\n",
       "       [2, 9, 8, 7]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape the array to remove the extra dimension\n",
    "# source_2 = source_2.reshape(-1, source_2.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training parameters\n",
    "ntokens = 10\n",
    "emsize = 20\n",
    "nhead = 4\n",
    "d_hid = 20\n",
    "nlayers = 2\n",
    "dropout = 0.03\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000\n",
    "num_models = 1  # Train 30 different models\n",
    "\n",
    "songStrings = np.array([\n",
    "   \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ\", # normal\n",
    "    \"JIHGFEDCBAJIHGFEDCBAJIHGFEDCBAJIHGFEDCBA\", # reverse\n",
    "])\n",
    "\n",
    "# Train and save multiple models\n",
    "for model_idx in range(num_models):\n",
    "    model_dir = f\"forward_prediction/model_1\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_2 = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "    model_2.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "    _, target = getTrainingData(songStrings, 2)\n",
    "    source_tensor = torch.tensor(source_2, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src = source_tensor.transpose(0, 1)\n",
    "        tgt = target_tensor.transpose(0, 1)\n",
    "\n",
    "        output = model_2(src)\n",
    "        loss = criterion(output.view(-1, model_2.ntokens), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_save_path = os.path.join(model_dir, 'model_2.pt')\n",
    "    torch.save(model_2.state_dict(), model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[7, 6, 7, 8]],\n",
       "\n",
       "       [[2, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[0, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[6, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[7, 6, 7, 8]],\n",
       "\n",
       "       [[2, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[0, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[6, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[7, 6, 7, 8]],\n",
       "\n",
       "       [[2, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[0, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[6, 1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3, 4]],\n",
       "\n",
       "       [[8, 3, 4, 5]],\n",
       "\n",
       "       [[3, 4, 5, 6]],\n",
       "\n",
       "       [[2, 5, 6, 7]],\n",
       "\n",
       "       [[7, 6, 7, 8]],\n",
       "\n",
       "       [[2, 7, 8, 9]],\n",
       "\n",
       "       [[5, 8, 9, 0]],\n",
       "\n",
       "       [[0, 9, 0, 1]],\n",
       "\n",
       "       [[5, 0, 1, 2]],\n",
       "\n",
       "       [[6, 1, 2, 3]],\n",
       "\n",
       "       [[6, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[0, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[2, 3, 2, 1]],\n",
       "\n",
       "       [[7, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[8, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[6, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[0, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[2, 3, 2, 1]],\n",
       "\n",
       "       [[7, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[8, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[6, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[0, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[2, 3, 2, 1]],\n",
       "\n",
       "       [[7, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[8, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]],\n",
       "\n",
       "       [[6, 7, 6, 5]],\n",
       "\n",
       "       [[5, 6, 5, 4]],\n",
       "\n",
       "       [[0, 5, 4, 3]],\n",
       "\n",
       "       [[5, 4, 3, 2]],\n",
       "\n",
       "       [[2, 3, 2, 1]],\n",
       "\n",
       "       [[7, 2, 1, 0]],\n",
       "\n",
       "       [[2, 1, 0, 9]],\n",
       "\n",
       "       [[3, 0, 9, 8]],\n",
       "\n",
       "       [[8, 9, 8, 7]],\n",
       "\n",
       "       [[1, 8, 7, 6]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "pred_2 = generate_predictions_for_current_model(model_2, source)\n",
    "pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(pred_2, target)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate and save predictions\n",
    "source_3 = generate_source_for_next_model(model_2, source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [8, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [2, 5, 6, 7],\n",
       "       [7, 6, 7, 8],\n",
       "       [2, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [0, 9, 0, 1],\n",
       "       [5, 0, 1, 2],\n",
       "       [6, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [8, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [2, 5, 6, 7],\n",
       "       [7, 6, 7, 8],\n",
       "       [2, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [0, 9, 0, 1],\n",
       "       [5, 0, 1, 2],\n",
       "       [6, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [8, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [2, 5, 6, 7],\n",
       "       [7, 6, 7, 8],\n",
       "       [2, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [0, 9, 0, 1],\n",
       "       [5, 0, 1, 2],\n",
       "       [6, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [8, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [2, 5, 6, 7],\n",
       "       [7, 6, 7, 8],\n",
       "       [2, 7, 8, 9],\n",
       "       [5, 8, 9, 0],\n",
       "       [0, 9, 0, 1],\n",
       "       [5, 0, 1, 2],\n",
       "       [1, 8, 7, 6],\n",
       "       [6, 7, 6, 5],\n",
       "       [5, 6, 5, 4],\n",
       "       [0, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [2, 3, 2, 1],\n",
       "       [7, 2, 1, 0],\n",
       "       [2, 1, 0, 9],\n",
       "       [3, 0, 9, 8],\n",
       "       [8, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [6, 7, 6, 5],\n",
       "       [5, 6, 5, 4],\n",
       "       [0, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [2, 3, 2, 1],\n",
       "       [7, 2, 1, 0],\n",
       "       [2, 1, 0, 9],\n",
       "       [3, 0, 9, 8],\n",
       "       [8, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [6, 7, 6, 5],\n",
       "       [5, 6, 5, 4],\n",
       "       [0, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [2, 3, 2, 1],\n",
       "       [7, 2, 1, 0],\n",
       "       [2, 1, 0, 9],\n",
       "       [3, 0, 9, 8],\n",
       "       [8, 9, 8, 7],\n",
       "       [1, 8, 7, 6],\n",
       "       [6, 7, 6, 5],\n",
       "       [5, 6, 5, 4],\n",
       "       [0, 5, 4, 3],\n",
       "       [5, 4, 3, 2],\n",
       "       [2, 3, 2, 1],\n",
       "       [7, 2, 1, 0],\n",
       "       [2, 1, 0, 9],\n",
       "       [3, 0, 9, 8],\n",
       "       [8, 9, 8, 7]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Mock predictions and target arrays\n",
    "pred = np.array([\n",
    "    [0, 1, 2, 3],\n",
    "    [1, 2, 3, 4],\n",
    "    [2, 3, 4, 5],\n",
    "    [3, 3, 5, 6],\n",
    "    [0, 1, 2, 3],  # Incorrect prediction\n",
    "])\n",
    "\n",
    "target = np.array([\n",
    "    [0, 1, 2, 3],\n",
    "    [1, 2, 3, 4],\n",
    "    [2, 3, 4, 5],\n",
    "    [3, 4, 5, 6],\n",
    "    [3, 4, 5, 6],  # Correct target\n",
    "])\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing saved predictions with the target.\n",
    "    \n",
    "    Args:\n",
    "    pred (np.ndarray): The predictions from the model.\n",
    "    target (np.ndarray): The true target data.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    # Flatten the predictions to match the target shape\n",
    "    all_predictions = pred.reshape(-1, pred.shape[-1])\n",
    "    \n",
    "    # Convert predictions and target to tensors\n",
    "    pred_tensor = torch.tensor(all_predictions, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = (pred_tensor == target_tensor).sum().item()\n",
    "    total = target_tensor.numel()\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(pred, target)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
